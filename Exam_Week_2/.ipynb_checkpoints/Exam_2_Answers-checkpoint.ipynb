{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exam 2 Answers by Javier López Rodríguez  (javier.lopez.rodriguez@alumnos.upm.es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1:  Controls\n",
    "\n",
    "Write a Python script that proves that the lines of data in Germplasm.tsv, and LocusGene are in the same sequence, based on the AGI Locus Code (ATxGxxxxxx).  (hint: This will help you decide how to load the data into the database)\n",
    "\n",
    "---------\n",
    "\n",
    "#### Explanation:\n",
    "\n",
    "We are dealing with .tsv files with headers. In order to read them, I'll use csv.DictReader because it is more efficient and easier (and I haven't used it before this course, unlike the normal python input/output, so it helps me practice new things).\n",
    "\n",
    "After opening both of the files, I first iterate through each file one time because I haven't found a method of csv.DictReader that returns its length. The object csv.DictReader is an iterator, so it doesn't load every line to memory at the same time, unlike a list. Therefore, converting it into a list in order to use len() is a memory dangerous process, so I avoided doing that.\n",
    "\n",
    "Then, I reset the pointer to the start and create the csv.DictReader objects for both files.\n",
    "\n",
    "Because we want to prove that both files have the same locus code in the same line, the number of lines should be the same in both cases. I check this (that's why I need to iterate the first time for the lengths). If the lengths aren't the same, it will only compare until the smallest file ends (minimum of length1 and length2).\n",
    "\n",
    "I create two lists for storing the line number of matches and mismatches (to check at the end if there is any mismatch, how many there are, and if the number of matches and mismatches is what we expected).\n",
    "\n",
    "Then, in a for loop, I iterate through both DictReaders at the same time, using the zip function. In case of different number of entries, zip stops when the smallest one ends (this is equivalent to iterating until the minimum of length1 and length2).\n",
    "\n",
    "I go through every pair of entries, store the Locus code (which DictReader makes very easy because each row is a dictionary and there's no need to split/do anything else), and compare both codes. I append the line number to either list, depending on it being a match or a mismatch.\n",
    "\n",
    " * Note that zip creates an iterator, not a list. Therefore, a zip of two DictReaders still does not load everything into memory at the same time, and the advantage of using DictReaders instead of turning everything into a list is maintained.\n",
    "\n",
    "In the end, I check if there are any mismatches (and print them), print the number of matches, and have a third condition just in case the number of matches + mismatches is less than the number of compared lines. The latter is just a precaution in case the code is incorrect, because (I think) it should never happen if the code is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both files have the same number of lines: 32 (without header).\n",
      "No mismatches found. There were 32 lines with matching Locus code.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename1 = \"LocusGene.tsv\"\n",
    "filename2 = \"Germplasm.tsv\"\n",
    "\n",
    "with open(filename1) as file1, open(filename2) as file2:\n",
    "        \n",
    "    # getting the length of each file iterating through each line and adding 1 for each line\n",
    "    # substracting 1 so that we don't count the header\n",
    "    length1 = sum(1 for _ in file1) - 1 \n",
    "    length2 = sum(1 for _ in file2) - 1 \n",
    "\n",
    "    # reset the pointer to the start of each file\n",
    "    file1.seek(0) \n",
    "    file2.seek(0)\n",
    "\n",
    "    # opening each file with csv.DictReader\n",
    "    locusgene = csv.DictReader(file1, delimiter=\"\\t\", quotechar='\"') # default fieldnames because of the header\n",
    "    germplasm = csv.DictReader(file2, delimiter=\"\\t\", quotechar='\"') # default fieldnames because of the header\n",
    "\n",
    "    if length1 != length2: # different number of lines\n",
    "        print(\"Warning: There are not the same number of lines in both files ({} and {})\".format(length1, length2))\n",
    "        print(\"Only the first {} lines of each file will be compared.\".format(min(length1, length2)))\n",
    "    else: # equal number of lines\n",
    "        print(\"Both files have the same number of lines: {} (without header).\".format(length1))\n",
    "\n",
    "    mismatched_lines = [] # will store the indexes of the mismatched lines, if any\n",
    "    correct_lines = [] # will store the indexes of the correct lines\n",
    "\n",
    "    # iterating through every pair of elements\n",
    "    linenumber = 1 # keeps track of the line number we're in, starts in 1 (because we skip the header using DictReader)\n",
    "    for entry1, entry2 in zip(locusgene, germplasm): # iterating through both DictReaders at the same time\n",
    "        locus1, locus2 = entry1[\"Locus\"], entry2[\"Locus\"]\n",
    "        #print(locus1 + \" \" + locus2) # checking that locus1 and locus2 contain the expected strings\n",
    "        # checking if they match or mismatch\n",
    "        if locus1 == locus2: # match\n",
    "            correct_lines.append(linenumber)\n",
    "        else: # mismatch\n",
    "            mismatched_lines.append(linenumber)\n",
    "        linenumber += 1 # increment linenumber\n",
    "        \n",
    "    if len(mismatched_lines) > 0: # there are mismatches, output them\n",
    "        print(\"Warning: There are some mismatches.\")\n",
    "        print(\"Mismatched lines: \" + \" \".join(mismatched_lines))\n",
    "        print(\"There were {} lines with matching Locus code.\".format(len(correct_lines)))\n",
    "    elif len(correct_lines) == min(length1, length2): # there are no mismatches and every line checked was a match\n",
    "        print(\"No mismatches found. There were {} lines with matching Locus code.\".format(len(correct_lines)))\n",
    "    else: # there are no mismatches but not every line checked was a match -> this should never happen\n",
    "        print(\"Error: there were less matches than expected. Something went wrong.\")\n",
    "\n",
    "# using \"with open(...) as ...\", we don't need to close the files afterwards, it is done automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem can be solved in a simpler way using the pandas library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in LocusGene.tsv is 32\n",
      "Number of items in Germplasm.tsv is 32\n",
      "Number of matching Locus codes: 32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename1 = \"LocusGene.tsv\"\n",
    "filename2 = \"Germplasm.tsv\"\n",
    "\n",
    "# reading the .tsv into pandas dataframes\n",
    "df1 = pd.read_csv(filename1, sep = \"\\t\")\n",
    "df2 = pd.read_csv(filename2, sep = \"\\t\")\n",
    "\n",
    "# renaming the columns so that, when concatenating the columns, they are named differently\n",
    "df1 = df1.rename(columns = {\"Locus\": \"Locus1\"})\n",
    "df2 = df2.rename(columns = {\"Locus\": \"Locus2\"})\n",
    "\n",
    "# printing number of items (size) of each column\n",
    "print(\"Number of items in \" + filename1 + \" is {}\".format(df1[\"Locus1\"].size))\n",
    "print(\"Number of items in \" + filename2 + \" is {}\".format(df2[\"Locus2\"].size))\n",
    "\n",
    "# concatenating both columns so that the following comparison can be made\n",
    "# if the number of elements is different, pd.concat adds NaN to the missing elements of the smallest column\n",
    "# so that both columns have the same length\n",
    "dfconcat = pd.concat([df1[\"Locus1\"], df2[\"Locus2\"]], axis = 1)\n",
    "\n",
    "# comparing the contents of both columns\n",
    "# the comparison gives a boolean array, the sum of that array is the number of True elements (number of matches)\n",
    "# doing this without concatenating both columns first gives an error if the number of elements is different,\n",
    "# that is why we need to concatenate both columns first into the same data frame\n",
    "print(\"Number of matching Locus codes: \" + str(sum(dfconcat[\"Locus1\"] == dfconcat[\"Locus2\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2:  Design and create the database\n",
    "* It should have two tables - one for each of the two data files.\n",
    "* The two tables should be linked in a 1:1 relationship\n",
    "* you may use either sqlMagic or pymysql to build the database\n",
    "\n",
    "---------\n",
    "\n",
    "# Explanation\n",
    "\n",
    "I'm using sqlMagic because I find it easier for creating databases and tables.\n",
    "\n",
    "We know that both files contain the same AGI Locus codes in the same positions, and both tables are going to have that field. \n",
    "\n",
    "Because the relationship between the two tables is 1:1 and the AGI Locus code in this case is a unique identifier of each entry in both tables, I am going to use it as the primary key of both tables. Therefore, the tables won't include additional numeric ids. Linking one table with the other in queries that involve both is going to happen via the AGI Locus codes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to sqlMagic\n",
    "%load_ext sql\n",
    "#%config SqlMagic.autocommit=False\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql create database examweek2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql use examweek2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "0 rows affected.\n",
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "3 rows affected.\n",
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "0 rows affected.\n",
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Field</th>\n",
       "        <th>Type</th>\n",
       "        <th>Null</th>\n",
       "        <th>Key</th>\n",
       "        <th>Default</th>\n",
       "        <th>Extra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>locus</td>\n",
       "        <td>varchar(10)</td>\n",
       "        <td>NO</td>\n",
       "        <td>PRI</td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>germplasm</td>\n",
       "        <td>varchar(20)</td>\n",
       "        <td>NO</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>phenotype</td>\n",
       "        <td>varchar(500)</td>\n",
       "        <td>NO</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>pubmed</td>\n",
       "        <td>int(11)</td>\n",
       "        <td>NO</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('locus', 'varchar(10)', 'NO', 'PRI', None, ''),\n",
       " ('germplasm', 'varchar(20)', 'NO', '', None, ''),\n",
       " ('phenotype', 'varchar(500)', 'NO', '', None, ''),\n",
       " ('pubmed', 'int(11)', 'NO', '', None, '')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql CREATE TABLE locusgene (locus VARCHAR(10) NOT NULL PRIMARY KEY, \\\n",
    "                             gene VARCHAR(10) NOT NULL, \\\n",
    "                             protein_length INTEGER NOT NULL);\n",
    "%sql DESCRIBE locusgene;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CREATE TABLE germplasm (locus VARCHAR(10) NOT NULL PRIMARY KEY, \\\n",
    "                             germplasm VARCHAR(20) NOT NULL, \\\n",
    "                             phenotype VARCHAR(500) NOT NULL, \\\n",
    "                             pubmed INTEGER NOT NULL);\n",
    "%sql DESCRIBE germplasm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Fill the database\n",
    "Using pymysql, create a Python script that reads the data from these files, and fills the database.  There are a variety of strategies to accomplish this.  I will give all strategies equal credit - do whichever one you are most confident with.\n",
    "\n",
    "------\n",
    "\n",
    "# Explain\n",
    "\n",
    "With the design I've chosen for the database, because the relationship is 1:1 and both of them have the same primary key and no additional id, it doesn't matter which table we fill out first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pymysql.cursors and connecting to the database\n",
    "import pymysql.cursors\n",
    "\n",
    "# Connecting to the database examweek2\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='examweek2', # database name\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor,\n",
    "                             autocommit = True) # I'm setting autocommit to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires to be connected to the database examweek2\n",
    "\n",
    "filename1 = \"LocusGene.tsv\"\n",
    "filename2 = \"Germplasm.tsv\"\n",
    "\n",
    "with open(filename1) as file1, open(filename2) as file2:\n",
    "    # opening each file with csv.DictReader\n",
    "    locusgene = csv.DictReader(file1, delimiter=\"\\t\", quotechar='\"') # default fieldnames because of the header\n",
    "    germplasm = csv.DictReader(file2, delimiter=\"\\t\", quotechar='\"') # default fieldnames because of the header\n",
    "    \n",
    "    # inserting locusgene entries into the database:\n",
    "    for row in locusgene:\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "            sql = \"\"\"INSERT INTO locusgene (locus, gene, protein_length) \n",
    "                     VALUES ('\"\"\" + row[\"Locus\"] + \"\"\"', '\"\"\" + row[\"Gene\"] + \"\"\"', \n",
    "                     \"\"\" + row[\"ProteinLength\"] + \"\"\" )\"\"\"\n",
    "            cursor.execute(sql)\n",
    "            # We don't need to store ids because there isn't any auto incremented id\n",
    "        except:\n",
    "            print(\"There was an error.\")\n",
    "            \n",
    "    # inserting germplasm entries into the database:\n",
    "    for row in germplasm:\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "            sql = \"\"\"INSERT INTO germplasm (locus, germplasm, phenotype, pubmed) \n",
    "                     VALUES ('\"\"\" + row[\"Locus\"] + \"\"\"', '\"\"\" + row[\"germplasm\"] + \"\"\"', \n",
    "                     '\"\"\" + row[\"phenotype\"] + \"\"\"', \"\"\" + row[\"pubmed\"] + \"\"\" )\"\"\" \n",
    "            cursor.execute(sql)\n",
    "        except:\n",
    "            print(\"There was an error.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Create reports, written to a file\n",
    "\n",
    "1. Create a report that shows the full, joined, content of the two database tables (including a header line)\n",
    "\n",
    "2. Create a joined report that only includes the Genes SKOR and MAA3\n",
    "\n",
    "3. Create a report that counts the number of entries for each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)\n",
    "\n",
    "4. Create a report that shows the average protein length for the genes on each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)\n",
    "\n",
    "When creating reports 2 and 3, remember the \"Don't Repeat Yourself\" rule! \n",
    "\n",
    "All reports should be written to **the same file**.  You may name the file anything you wish.\n",
    "\n",
    "---------\n",
    "\n",
    "# Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires to be connected to the database examweek2 (should already be connected from problem 3)\n",
    "#connection = pymysql.connect(host='localhost',\n",
    "#                             user='root',\n",
    "#                             password='root',\n",
    "#                             db='examweek2', # database name\n",
    "#                             charset='utf8mb4',  \n",
    "#                             cursorclass=pymysql.cursors.DictCursor,\n",
    "#                             autocommit = True) # I'm setting autocommit to True\n",
    "\n",
    "\n",
    "\n",
    "### Report 1\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        # Performs a full outer join to read everything from both tables. \n",
    "        # In this case, any join would be equivalent because every locus exists in both tables. \n",
    "        sql = \"\"\"SELECT * FROM locusgene FULL OUTER JOIN germplasm \n",
    "                 ON germplasm.locus = locusgene.locus;\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        for result in results:\n",
    "            print(result)\n",
    "            print()\n",
    "finally:\n",
    "    print(\"\")\n",
    "\n",
    "### Report 2\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        # Performs a full outer join to read everything from both tables. \n",
    "        # In this case, any join would be equivalent because every locus exists in both tables. \n",
    "        sql = \"\"\"SELECT * FROM locusgene FULL OUTER JOIN germplasm \n",
    "                 ON germplasm.locus = locusgene.locus \n",
    "                 WHERE locusgene.gene = 'SKOR' OR locusgene.gene = 'MAA3' ;\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        for result in results:\n",
    "            print(result)\n",
    "            print()\n",
    "finally:\n",
    "    print(\"\")\n",
    "\n",
    "### Report 3\n",
    "## Creating a function:\n",
    "def count_regex_in_field(regex, fieldname, tablename):\n",
    "    \"\"\"\n",
    "    Counts the number of entries of a table that match a regular expression in one of its fields.\n",
    "    Requires an open pymysql connection to the database.\n",
    "    \n",
    "    Parameters:\n",
    "    regex: regular expression (in sql format)\n",
    "    fieldname: the name of the field (column) of the table\n",
    "    tablename: the name of the table\n",
    "    \n",
    "    Returns: the number of entries, or None if there was an error.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            sql = \"\"\"SELECT COUNT(*) AS 'Number of matches' FROM \"\"\" + tablename + \"\"\" \n",
    "                     WHERE \"\"\" + fieldname + \"\"\" REGEXP '\"\"\" + regex + \"\"\"'; \"\"\"\n",
    "            cursor.execute(sql)\n",
    "            results = cursor.fetchall()\n",
    "            count = results[0][\"Number of matches\"]\n",
    "    except:\n",
    "        print(\"There was an error.\")\n",
    "        count = None\n",
    "    return count\n",
    "\n",
    "## Generating the report:\n",
    "# creates a list of the corresponding regex for the chromosomes 1 to 5 (0 to 4, +1)\n",
    "chromosome_regexs = [\"AT\" + str(num + 1) + \"G[0-9]{5}\" for num in range(5)]\n",
    "\n",
    "num_of_entries = {} # chromosome number : number of entries\n",
    "for chr_regex in chromosome_regexs:\n",
    "    count = count_regex_in_field(regex = chr_regex, fieldname = \"locus\", tablename = \"locusgene\")\n",
    "    num_of_entries[chr_regex[2]] = count # index 2 of the regex is the chromosome number\n",
    "\n",
    "### Report 4\n",
    "## Creating a function:\n",
    "def mean_of_field_where_regex_in_field(mean_fieldname, regex, regex_fieldname, tablename):\n",
    "    \"\"\"\n",
    "    Given a table, calculates the mean of the elements of a field \n",
    "    of every entry in which another field matches a regular expression.\n",
    "    Requires an open pymysql connection to the database.\n",
    "    \n",
    "    Parameters:\n",
    "    mean_fieldname: the name of the field where the mean is going to be computed\n",
    "    regex: the regular expression to match on field regex_fieldname\n",
    "    regex_fieldname: the name of the field where the regular expression is going to be matched\n",
    "    tablename: the name of the table\n",
    "    \n",
    "    Returns: the mean of the elements, or None if there was an error.\n",
    "    \"\"\"\n",
    "    # requires an open connection to the database\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            sql = \"\"\"SELECT AVG(\"\"\" + mean_fieldname + \"\"\") AS 'Average' FROM \"\"\" + tablename + \"\"\" \n",
    "                     WHERE \"\"\" + fieldname + \"\"\" REGEXP '\"\"\" + regex + \"\"\"'; \"\"\"\n",
    "            cursor.execute(sql)\n",
    "            results = cursor.fetchall()\n",
    "            average = results[0][\"Average\"]\n",
    "    except:\n",
    "        print(\"There was an error.\")\n",
    "        average = None\n",
    "    return average\n",
    "\n",
    "## Generating a report:\n",
    "# we already have the chromosome_regexs list\n",
    "#chromosome_regexs = [\"AT\" + str(num + 1) + \"G[0-9]{5}\" for num in range(5)]\n",
    "\n",
    "average_lengths = {} # chromosome number : average protein length\n",
    "for chr_regex in chromosome_regexs:\n",
    "    average = mean_of_field_where_regex_in_field(mean_fieldname = \"protein_length\", regex = chr_regex, \n",
    "                                                regex_fieldname = \"locus\", tablename = \"locusgene\")\n",
    "    average_lengths[chr_regex[2]] = average # index 2 of the regex is the chromosome number\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosome_regexs = [\"AT\" + str(num + 1) + \"G[0-9]{5}\" for num in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AT1G[0-9]{5}', 'AT2G[0-9]{5}', 'AT3G[0-9]{5}', 'AT4G[0-9]{5}', 'AT5G[0-9]{5}']\n"
     ]
    }
   ],
   "source": [
    "print(chromosome_regexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
